{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786",
   "metadata": {
    "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786"
   },
   "source": [
    "# Lab | Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8882fc-4815-4567-92fa-b4816358ba7d",
   "metadata": {
    "id": "ce8882fc-4815-4567-92fa-b4816358ba7d",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Welcome to the \"Books to Scrape\" Web Scraping Adventure Lab!\n",
    "\n",
    "**Objective**\n",
    "\n",
    "In this lab, we will embark on a mission to unearth valuable insights from the data available on Books to Scrape, an online platform showcasing a wide variety of books. As data analyst, you have been tasked with scraping a specific subset of book data from Books to Scrape to assist publishing companies in understanding the landscape of highly-rated books across different genres. Your insights will help shape future book marketing strategies and publishing decisions.\n",
    "\n",
    "**Background**\n",
    "\n",
    "In a world where data has become the new currency, businesses are leveraging big data to make informed decisions that drive success and profitability. The publishing industry, much like others, utilizes data analytics to understand market trends, reader preferences, and the performance of books based on factors such as genre, author, and ratings. Books to Scrape serves as a rich source of such data, offering detailed information about a diverse range of books, making it an ideal platform for extracting insights to aid in informed decision-making within the literary world.\n",
    "\n",
    "**Task**\n",
    "\n",
    "Your task is to create a Python script using BeautifulSoup and pandas to scrape Books to Scrape book data, focusing on book ratings and genres. The script should be able to filter books with ratings above a certain threshold and in specific genres. Additionally, the script should structure the scraped data in a tabular format using pandas for further analysis.\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`. The function should scrape book data from the \"Books to Scrape\" website and return a `pandas` DataFrame with the following columns:\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "- A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`.\n",
    "- The function should return a DataFrame with the following columns:\n",
    "  - **UPC**: The Universal Product Code (UPC) of the book.\n",
    "  - **Title**: The title of the book.\n",
    "  - **Price (£)**: The price of the book in pounds.\n",
    "  - **Rating**: The rating of the book (1-5 stars).\n",
    "  - **Genre**: The genre of the book.\n",
    "  - **Availability**: Whether the book is in stock or not.\n",
    "  - **Description**: A brief description or product description of the book (if available).\n",
    "  \n",
    "You will execute this script to scrape data for books with a minimum rating of `4.0 and above` and a maximum price of `£20`. \n",
    "\n",
    "Remember to experiment with different ratings and prices to ensure your code is versatile and can handle various searches effectively!\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "- [Books to Scrape](https://books.toscrape.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519921d-5890-445b-9a33-934ed8ee378c",
   "metadata": {
    "id": "3519921d-5890-445b-9a33-934ed8ee378c",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Hint**\n",
    "\n",
    "Your first mission is to familiarize yourself with the **Books to Scrape** website. Navigate to [Books to Scrape](http://books.toscrape.com/) and explore the available books to understand their layout and structure. \n",
    "\n",
    "Next, think about how you can set parameters for your data extraction:\n",
    "\n",
    "- **Minimum Rating**: Focus on books with a rating of 4.0 and above.\n",
    "- **Maximum Price**: Filter for books priced up to £20.\n",
    "\n",
    "After reviewing the site, you can construct a plan for scraping relevant data. Pay attention to the details displayed for each book, including the title, price, rating, and availability. This will help you identify the correct HTML elements to target with your scraping script.\n",
    "\n",
    "Make sure to build your scraping URL and logic based on the patterns you observe in the HTML structure of the book listings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a83a0d-a742-49f6-985e-e27887cbf922",
   "metadata": {
    "id": "25a83a0d-a742-49f6-985e-e27887cbf922"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Best of luck! Immerse yourself in the world of books, and may the data be with you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0",
   "metadata": {
    "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Important Note**:\n",
    "\n",
    "In the fast-changing online world, websites often update and change their structures. When you try this lab, the **Books to Scrape** website might differ from what you expect.\n",
    "\n",
    "If you encounter issues due to these changes, like new rules or obstacles preventing data extraction, don’t worry! Get creative.\n",
    "\n",
    "You can choose another website that interests you and is suitable for scraping data. Options like Wikipedia, The New York Times, or even library databases are great alternatives. The main goal remains the same: extract useful data and enhance your web scraping skills while exploring a source of information you enjoy. This is your opportunity to practice and adapt to different web environments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40359eee-9cd7-4884-bfa4-83344c222305",
   "metadata": {
    "id": "40359eee-9cd7-4884-bfa4-83344c222305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution goes here\n",
    "\"\"\"\n",
    "# Let's start importing the stuff:\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Now the url and check status:\n",
    "url = \"https://books.toscrape.com/\"\n",
    "response = requests.get(url)\n",
    "response.status_code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfb06426-8ba5-4a1d-87cf-7a34e6434cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# The provided code retrieves the webpage content from the given URL and saves it in a response object.\\n# This object possesses either a text or content attribute, holding the HTML code similar to what we observe when inspecting the source in a web browser.\\n\\nresponse.content\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# The provided code retrieves the webpage content from the given URL and saves it in a response object.\n",
    "# This object possesses either a text or content attribute, holding the HTML code similar to what we observe when inspecting the source in a web browser.\n",
    "\n",
    "response.content\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9671f5-2dad-410a-8a43-b8a170e2c8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# The code above parses the HTML (stored in response.content) into a special object called soup that the Beautiful Soup library understands.\n",
    "# In other words, Beautiful Soup is reading the HTML and making sense of its structure.\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "type(soup) # Now the object is a bs4.BeautifulSoup\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa82b31c-1db9-457f-b94e-324da141fd03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(soup.prettify()) # With this format we can read the HTML much better, in the inspector way\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(soup.prettify()) # With this format we can read the HTML much better, in the inspector way\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be899d7-71c5-439d-b321-caca9a83c262",
   "metadata": {},
   "source": [
    "**Task**\n",
    "\n",
    "Your task is to create a Python script using BeautifulSoup and pandas to scrape Books to Scrape book data, focusing on book ratings and genres. The script should be able to filter books with ratings above a certain threshold and in specific genres. Additionally, the script should structure the scraped data in a tabular format using pandas for further analysis.\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`. The function should scrape book data from the \"Books to Scrape\" website and return a `pandas` DataFrame with the following columns:\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "- A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`.\n",
    "- The function should return a DataFrame with the following columns:\n",
    "  - **UPC**: The Universal Product Code (UPC) of the book.\n",
    "  - **Title**: The title of the book.\n",
    "  - **Price (£)**: The price of the book in pounds.\n",
    "  - **Rating**: The rating of the book (1-5 stars).\n",
    "  - **Genre**: The genre of the book.\n",
    "  - **Availability**: Whether the book is in stock or not.\n",
    "  - **Description**: A brief description or product description of the book (if available).\n",
    "  \n",
    "You will execute this script to scrape data for books with a minimum rating of `4.0 and above` and a maximum price of `£20`. \n",
    "\n",
    "Remember to experiment with different ratings and prices to ensure your code is versatile and can handle various searches effectively!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e907509-e4c9-4332-8145-55b47025b323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbooks = soup.find_all(class_=\"product_pod\")  #the soup containing the minor element with all the data for one book only, we apply .find_all to capture all books\\nprint(books)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "books = soup.find_all(class_=\"product_pod\")  #the soup containing the minor element with all the data for one book only, we apply .find_all to capture all books\n",
    "print(books)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2028de-ddc5-4319-b2e1-348948d3200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# lets export the element titles only one by one:\\n\\nbook_titles = [] # creating the list\\n\\nfor book in books:\\n    title = book.find('h3').find('a').get('title')\\n    book_titles.append(title)\\n    \\nprint(book_titles) # it worked! :)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# lets export the element titles only one by one:\n",
    "\n",
    "book_titles = [] # creating the list\n",
    "\n",
    "for book in books:\n",
    "    title = book.find('h3').find('a').get('title')\n",
    "    book_titles.append(title)\n",
    "    \n",
    "print(book_titles) # it worked! :)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c97df4a-c3e6-470c-ae78-b1987390c306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbook_prices = [] # creating the list\\n\\nfor book in books:\\n    price = book.find('p', class_='price_color').get_text()\\n    book_prices.append(price)\\n    \\nprint(book_prices) # it worked! :)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "book_prices = [] # creating the list\n",
    "\n",
    "for book in books:\n",
    "    price = book.find('p', class_='price_color').get_text()\n",
    "    book_prices.append(price)\n",
    "    \n",
    "print(book_prices) # it worked! :)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04c28af-e60c-4791-9dd5-142084abbee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# extracting the ratings:\\n# Locate the \\'p\\' tag with the class containing \\'star-rating\\'\\nstar_tag = soup.find(\\'p\\', class_=\\'star-rating\\')\\n\\n# Extract full class name\\nstar_rating_class = \" \".join(star_tag.get(\"class\"))\\n\\n# Print the extracted star rating class\\nprint(\"Star Rating Class:\", star_rating_class)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# extracting the ratings:\n",
    "# Locate the 'p' tag with the class containing 'star-rating'\n",
    "star_tag = soup.find('p', class_='star-rating')\n",
    "\n",
    "# Extract full class name\n",
    "star_rating_class = \" \".join(star_tag.get(\"class\"))\n",
    "\n",
    "# Print the extracted star rating class\n",
    "print(\"Star Rating Class:\", star_rating_class)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc1e4a2-ca74-4cf2-a473-b50b74d735ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstar_rating_class = (\" \".join((soup.find(\\'p\\', class_=\\'star-rating\\')).get(\"class\"))).split()[1] #all the above merged + split to grab only the \"Three\" by index\\nstar_rating_class\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "star_rating_class = (\" \".join((soup.find('p', class_='star-rating')).get(\"class\"))).split()[1] #all the above merged + split to grab only the \"Three\" by index\n",
    "star_rating_class\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d76ab03f-41b4-476e-856d-399227137d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# now applying the loop:\\nbook_ratings = []\\n\\nfor book in books:\\n    rating = (\" \".join((soup.find(\\'p\\', class_=\\'star-rating\\')).get(\"class\"))).split()[1]\\n\\n    book_ratings.append(rating)\\n    \\nprint(book_ratings) # it worked! :)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# now applying the loop:\n",
    "book_ratings = []\n",
    "\n",
    "for book in books:\n",
    "    rating = (\" \".join((soup.find('p', class_='star-rating')).get(\"class\"))).split()[1]\n",
    "\n",
    "    book_ratings.append(rating)\n",
    "    \n",
    "print(book_ratings) # it worked! :)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf620ad-f93c-415a-9aa4-3cd418081aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# time for availability:\\nbook_availabilities = [] # creating the list\\n\\nfor book in books:\\n    availability = book.find('p', class_='instock availability').get_text(strip=True) \\n    # .get_text(strip=True): Retrieves and cleans the object leaving only the text inside\\n    book_availabilities.append(availability)\\n    \\nprint(book_availabilities) # it worked! :)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# time for availability:\n",
    "book_availabilities = [] # creating the list\n",
    "\n",
    "for book in books:\n",
    "    availability = book.find('p', class_='instock availability').get_text(strip=True) \n",
    "    # .get_text(strip=True): Retrieves and cleans the object leaving only the text inside\n",
    "    book_availabilities.append(availability)\n",
    "    \n",
    "print(book_availabilities) # it worked! :)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91bb958-3e26-456b-9b66-3d594b6b5621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# some data will be more complicated because we find because we find it inside the book's link (Description and UPC)\\nbook_links = [] # creating the list of links\\n\\nfor book in books:\\n    book_link = url+(book.find('h3').find('a').get('href')) # concatenating the url to have the complete link\\n    book_links.append(book_link) \\n    \\nprint(book_links) # it worked! :)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# some data will be more complicated because we find because we find it inside the book's link (Description and UPC)\n",
    "book_links = [] # creating the list of links\n",
    "\n",
    "for book in books:\n",
    "    book_link = url+(book.find('h3').find('a').get('href')) # concatenating the url to have the complete link\n",
    "    book_links.append(book_link) \n",
    "    \n",
    "print(book_links) # it worked! :)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc0dc173-3cb9-4b90-9c40-409fada1368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a897fe39b1053632', '90fa61229261140a', '6957f44c3847a760', 'e00eb4fd7b871a48', '4165285e1663650f', 'f77dbf2323deb740', '2597b5a345f45e1b', 'e72a5dfc7e9267b2', 'e10e1e165dc8be4a', '1dfe412b8ac00530', '0312262ecafa5a40', '30a7f60cd76ca58c', 'ce6396b0f23f6ecc', '3b1c02bac2a429e6', 'a34ba96d4081e6a4', 'deda3e61b9514b83', 'feb7cc7701ecf901', 'e30f54cea9b38190', 'a18a4f574854aced', 'a22124811bfa8350']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# try to use the new links to capture UPC:\n",
    "book_codes = [] # creating the list of links\n",
    "\n",
    "for book in books:\n",
    "    book_link = url+(book.find('h3').find('a').get('href')) # concatenating the url to have the complete link\n",
    "    book_response = requests.get(book_link)\n",
    "    book_soup = BeautifulSoup(book_response.content, \"html.parser\") # new soup for the new URL\n",
    "    code = book_soup.find(class_=\"table table-striped\").find('th', string='UPC').find_next_sibling('td').get_text(strip=True)\n",
    "    book_codes.append(code)\n",
    "    \n",
    "print(book_codes) # it worked! :)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3324a9be-3035-4937-a6d6-6acca70b1bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# now same but Description:\\nbook_link = url+(book.find(\\'h3\\').find(\\'a\\').get(\\'href\\')) # concatenating the url to have the complete link\\nbook_response = requests.get(book_link)\\nbook_soup = BeautifulSoup(book_response.content, \"html.parser\")\\n\\ndescription_meta = book_soup.find(\\'meta\\', {\\'name\\': \\'description\\'})\\nif description_meta:\\n    description = description_meta.get(\\'content\\')\\n\\n# Print the extracted description\\nprint(description)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# now same but Description:\n",
    "book_link = url+(book.find('h3').find('a').get('href')) # concatenating the url to have the complete link\n",
    "book_response = requests.get(book_link)\n",
    "book_soup = BeautifulSoup(book_response.content, \"html.parser\")\n",
    "\n",
    "description_meta = book_soup.find('meta', {'name': 'description'})\n",
    "if description_meta:\n",
    "    description = description_meta.get('content')\n",
    "\n",
    "# Print the extracted description\n",
    "print(description)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "959c32b2-cc6a-4647-9f55-23c52a02554a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndescription = (book_soup.find(\\'meta\\', {\\'name\\': \\'description\\'})).get(\"content\").strip() #same but only one line\\ndescription\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "description = (book_soup.find('meta', {'name': 'description'})).get(\"content\").strip() #same but only one line\n",
    "description\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e3ed319-deed-4631-860c-26507f60bde1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# now lets create the loop:\\nbook_descriptions = [] # creating the list of links\\n\\nfor book in books:\\n    book_link = url+(book.find(\\'h3\\').find(\\'a\\').get(\\'href\\')) # concatenating the url to have the complete link\\n    book_response = requests.get(book_link)\\n    book_soup = BeautifulSoup(book_response.content, \"html.parser\") # new soup for the new URL\\n    description = (book_soup.find(\\'meta\\', {\\'name\\': \\'description\\'})).get(\"content\").strip()\\n    # soup.find(\\'meta\\', {\\'name\\': \\'description\\'}): Finds the <meta> tag with the attribute name=\"description\". This assumes the description is stored in the content attribute of this meta tag.\\n    book_descriptions.append(description)\\n    \\nprint(book_descriptions) # it worked! :)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# now lets create the loop:\n",
    "book_descriptions = [] # creating the list of links\n",
    "\n",
    "for book in books:\n",
    "    book_link = url+(book.find('h3').find('a').get('href')) # concatenating the url to have the complete link\n",
    "    book_response = requests.get(book_link)\n",
    "    book_soup = BeautifulSoup(book_response.content, \"html.parser\") # new soup for the new URL\n",
    "    description = (book_soup.find('meta', {'name': 'description'})).get(\"content\").strip()\n",
    "    # soup.find('meta', {'name': 'description'}): Finds the <meta> tag with the attribute name=\"description\". This assumes the description is stored in the content attribute of this meta tag.\n",
    "    book_descriptions.append(description)\n",
    "    \n",
    "print(book_descriptions) # it worked! :)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b0cf737-247f-432a-81e2-fc2e642c9cda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Find all genre links from the sidebar\\ngenres = soup.find('ul', class_='nav nav-list').find('ul').find_all('li')\\n\\n# Initialize a dictionary to store book titles by genre\\nbooks_by_genre = {}\\n\\n# Iterate over each genre\\nfor genre in genres:\\n    # Extract genre name and full URL\\n    genre_name = genre.find('a').get_text(strip=True)\\n    genre_url = url + genre.find('a')['href']\\n    \\n    # Initialize a list to store book titles for this genre\\n    books_by_genre[genre_name] = []\\n   \\n    # Handle pagination to fetch all books in the genre\\n    page_url = genre_url\\n    while True:\\n        # Request the genre page\\n        genre_page = requests.get(page_url)\\n        genre_soup = BeautifulSoup(genre_page.content, 'html.parser')\\n\\n        # Find all books on the current page\\n        books = genre_soup.find_all('article', class_='product_pod')\\n        \\n        # Extract and collect book titles\\n        for book in books:\\n            title = book.find('h3').find('a')['title']\\n            books_by_genre[genre_name].append(title)\\n\\n        # Check for a next page link\\n        next_button = genre_soup.find('li', class_='next')\\n        if next_button:\\n            relative_next_url = next_button.find('a')['href']\\n            # Construct the URL for the next page\\n            if 'catalogue/' not in page_url:\\n                page_url = url + 'catalogue/' + relative_next_url\\n            else:\\n                page_url = url + relative_next_url\\n                \\n            time.sleep(1)  # Delay for politeness\\n        else:\\n            break  # No more pages, exit loop\\n\\nprint(books_by_genre)\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Find all genre links from the sidebar\n",
    "genres = soup.find('ul', class_='nav nav-list').find('ul').find_all('li')\n",
    "\n",
    "# Initialize a dictionary to store book titles by genre\n",
    "books_by_genre = {}\n",
    "\n",
    "# Iterate over each genre\n",
    "for genre in genres:\n",
    "    # Extract genre name and full URL\n",
    "    genre_name = genre.find('a').get_text(strip=True)\n",
    "    genre_url = url + genre.find('a')['href']\n",
    "    \n",
    "    # Initialize a list to store book titles for this genre\n",
    "    books_by_genre[genre_name] = []\n",
    "   \n",
    "    # Handle pagination to fetch all books in the genre\n",
    "    page_url = genre_url\n",
    "    while True:\n",
    "        # Request the genre page\n",
    "        genre_page = requests.get(page_url)\n",
    "        genre_soup = BeautifulSoup(genre_page.content, 'html.parser')\n",
    "\n",
    "        # Find all books on the current page\n",
    "        books = genre_soup.find_all('article', class_='product_pod')\n",
    "        \n",
    "        # Extract and collect book titles\n",
    "        for book in books:\n",
    "            title = book.find('h3').find('a')['title']\n",
    "            books_by_genre[genre_name].append(title)\n",
    "\n",
    "        # Check for a next page link\n",
    "        next_button = genre_soup.find('li', class_='next')\n",
    "        if next_button:\n",
    "            relative_next_url = next_button.find('a')['href']\n",
    "            # Construct the URL for the next page\n",
    "            if 'catalogue/' not in page_url:\n",
    "                page_url = url + 'catalogue/' + relative_next_url\n",
    "            else:\n",
    "                page_url = url + relative_next_url\n",
    "                \n",
    "            time.sleep(1)  # Delay for politeness\n",
    "        else:\n",
    "            break  # No more pages, exit loop\n",
    "\n",
    "print(books_by_genre)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62dc4699-5d75-49f8-bf70-2fb438f5d9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntype(books_by_genre) # now we have a dictionary with all the books gouped by title\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "type(books_by_genre) # now we have a dictionary with all the books gouped by title\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a94e5b-4f83-4818-aa17-7aac98b9c036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngenre = next((genre for genre, titles in books_by_genre.items() if title in titles), None)\\nprint(genre)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "genre = next((genre for genre, titles in books_by_genre.items() if title in titles), None)\n",
    "print(genre)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7214e34-2759-46d6-9e54-aa429938522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbook_titles = [] # creating the list\\nbook_genres = []\\n\\nfor book in books:\\n    title = book.find('h3').find('a').get('title')\\n    book_titles.append(title)\\n    genre = next((genre for genre, titles in books_by_genre.items() if title in titles), None)\\n    book_genres.append(genre)\\n    \\nprint(book_titles)\\nprint(book_genres)\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "book_titles = [] # creating the list\n",
    "book_genres = []\n",
    "\n",
    "for book in books:\n",
    "    title = book.find('h3').find('a').get('title')\n",
    "    book_titles.append(title)\n",
    "    genre = next((genre for genre, titles in books_by_genre.items() if title in titles), None)\n",
    "    book_genres.append(genre)\n",
    "    \n",
    "print(book_titles)\n",
    "print(book_genres)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480e866c-f4c7-436d-9963-54c51739fd3d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPC</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a897fe39b1053632</td>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>It's hard to imagine a world without A Light i...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90fa61229261140a</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>\"Erotic and absorbing...Written with starling ...</td>\n",
       "      <td>Historical Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6957f44c3847a760</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Dans une France assez proche de la nôtre, un h...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4165285e1663650f</td>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>From a renowned historian comes a groundbreaki...</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f77dbf2323deb740</td>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>£22.65</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Patient Twenty-nine.A monster roams the halls ...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2597b5a345f45e1b</td>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>£33.34</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Drawing on his extensive experience evaluating...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e72a5dfc7e9267b2</td>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>£17.93</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>\"If you have a heart, if you have a soul, Kare...</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e10e1e165dc8be4a</td>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>£22.60</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>For readers of Laura Hillenbrand's Seabiscuit ...</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1dfe412b8ac00530</td>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>£52.15</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Praise for Aracelis Girmay:\"[Girmay's] every l...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0312262ecafa5a40</td>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>£13.99</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Since her assault, Miss Annette Chetwynd has b...</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30a7f60cd76ca58c</td>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>£20.66</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>This book is an important and complete collect...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ce6396b0f23f6ecc</td>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>£17.46</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Aaron Ledbetter’s future had been planned out ...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3b1c02bac2a429e6</td>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>£52.29</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Scott Pilgrim's life is totally sweet. He's 23...</td>\n",
       "      <td>Sequential Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a34ba96d4081e6a4</td>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>£35.02</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Punk's raw power rejuvenated rock, but by the ...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>deda3e61b9514b83</td>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>£57.25</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>This is the never-before-told story of the mus...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feb7cc7701ecf901</td>\n",
       "      <td>Olio</td>\n",
       "      <td>£23.88</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Part fact, part fiction, Tyehimba Jess's much ...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>e30f54cea9b38190</td>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>£37.59</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Andrew Barger, award-winning author and engine...</td>\n",
       "      <td>Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a18a4f574854aced</td>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>£51.33</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Libertarianism isn't about winning elections; ...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a22124811bfa8350</td>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>“Wherever you go, whatever you do, just . . . ...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UPC                                              Title  \\\n",
       "0   a897fe39b1053632                               A Light in the Attic   \n",
       "1   90fa61229261140a                                 Tipping the Velvet   \n",
       "2   6957f44c3847a760                                         Soumission   \n",
       "3   e00eb4fd7b871a48                                      Sharp Objects   \n",
       "4   4165285e1663650f              Sapiens: A Brief History of Humankind   \n",
       "5   f77dbf2323deb740                                    The Requiem Red   \n",
       "6   2597b5a345f45e1b  The Dirty Little Secrets of Getting Your Dream...   \n",
       "7   e72a5dfc7e9267b2  The Coming Woman: A Novel Based on the Life of...   \n",
       "8   e10e1e165dc8be4a  The Boys in the Boat: Nine Americans and Their...   \n",
       "9   1dfe412b8ac00530                                    The Black Maria   \n",
       "10  0312262ecafa5a40     Starving Hearts (Triangular Trade Trilogy, #1)   \n",
       "11  30a7f60cd76ca58c                              Shakespeare's Sonnets   \n",
       "12  ce6396b0f23f6ecc                                        Set Me Free   \n",
       "13  3b1c02bac2a429e6  Scott Pilgrim's Precious Little Life (Scott Pi...   \n",
       "14  a34ba96d4081e6a4                          Rip it Up and Start Again   \n",
       "15  deda3e61b9514b83  Our Band Could Be Your Life: Scenes from the A...   \n",
       "16  feb7cc7701ecf901                                               Olio   \n",
       "17  e30f54cea9b38190  Mesaerion: The Best Science Fiction Stories 18...   \n",
       "18  a18a4f574854aced                       Libertarianism for Beginners   \n",
       "19  a22124811bfa8350                            It's Only the Himalayas   \n",
       "\n",
       "     Price Rating Availability  \\\n",
       "0   £51.77  Three     In stock   \n",
       "1   £53.74  Three     In stock   \n",
       "2   £50.10  Three     In stock   \n",
       "3   £47.82  Three     In stock   \n",
       "4   £54.23  Three     In stock   \n",
       "5   £22.65  Three     In stock   \n",
       "6   £33.34  Three     In stock   \n",
       "7   £17.93  Three     In stock   \n",
       "8   £22.60  Three     In stock   \n",
       "9   £52.15  Three     In stock   \n",
       "10  £13.99  Three     In stock   \n",
       "11  £20.66  Three     In stock   \n",
       "12  £17.46  Three     In stock   \n",
       "13  £52.29  Three     In stock   \n",
       "14  £35.02  Three     In stock   \n",
       "15  £57.25  Three     In stock   \n",
       "16  £23.88  Three     In stock   \n",
       "17  £37.59  Three     In stock   \n",
       "18  £51.33  Three     In stock   \n",
       "19  £45.17  Three     In stock   \n",
       "\n",
       "                                          Description               Genre  \n",
       "0   It's hard to imagine a world without A Light i...              Poetry  \n",
       "1   \"Erotic and absorbing...Written with starling ...  Historical Fiction  \n",
       "2   Dans une France assez proche de la nôtre, un h...             Fiction  \n",
       "3   WICKED above her hipbone, GIRL across her hear...             Mystery  \n",
       "4   From a renowned historian comes a groundbreaki...             History  \n",
       "5   Patient Twenty-nine.A monster roams the halls ...         Young Adult  \n",
       "6   Drawing on his extensive experience evaluating...            Business  \n",
       "7   \"If you have a heart, if you have a soul, Kare...             Default  \n",
       "8   For readers of Laura Hillenbrand's Seabiscuit ...             Default  \n",
       "9   Praise for Aracelis Girmay:\"[Girmay's] every l...              Poetry  \n",
       "10  Since her assault, Miss Annette Chetwynd has b...             Default  \n",
       "11  This book is an important and complete collect...              Poetry  \n",
       "12  Aaron Ledbetter’s future had been planned out ...         Young Adult  \n",
       "13  Scott Pilgrim's life is totally sweet. He's 23...      Sequential Art  \n",
       "14  Punk's raw power rejuvenated rock, but by the ...               Music  \n",
       "15  This is the never-before-told story of the mus...               Music  \n",
       "16  Part fact, part fiction, Tyehimba Jess's much ...              Poetry  \n",
       "17  Andrew Barger, award-winning author and engine...     Science Fiction  \n",
       "18  Libertarianism isn't about winning elections; ...            Politics  \n",
       "19  “Wherever you go, whatever you do, just . . . ...              Travel  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VICTOR CODE! Works properly to gather UPC\tTitle\tPrice\tRating\tAvailability\tDescription and Genre!\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def extract_books_info(url):\n",
    "    # Make a request to the provided URL\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Creating the lists to store the data\n",
    "    book_codes = []\n",
    "    book_titles = []\n",
    "    book_prices = []\n",
    "    book_ratings = []\n",
    "    book_availabilities = []\n",
    "    book_descriptions = []\n",
    "    book_genres = []\n",
    "\n",
    "    books = soup.find_all(class_=\"product_pod\")\n",
    "\n",
    "    for book in books:\n",
    "        title = book.find('h3').find('a').get('title')\n",
    "        book_titles.append(title)\n",
    "        \n",
    "        price = book.find('p', class_='price_color').get_text()\n",
    "        book_prices.append(price)\n",
    "        \n",
    "        rating = (\" \".join((soup.find('p', class_='star-rating')).get(\"class\"))).split()[1]\n",
    "        book_ratings.append(rating)\n",
    "\n",
    "        availability = book.find('p', class_='instock availability').get_text(strip=True)\n",
    "        book_availabilities.append(availability)\n",
    "        \n",
    "        book_link = url + (book.find('h3').find('a').get('href'))\n",
    "        book_response = requests.get(book_link)\n",
    "        book_soup = BeautifulSoup(book_response.content, \"html.parser\")\n",
    "        code = book_soup.find(class_=\"table table-striped\").find('th', string='UPC').find_next_sibling('td').get_text(strip=True)\n",
    "        book_codes.append(code)\n",
    "\n",
    "        description = (book_soup.find('meta', {'name': 'description'})).get(\"content\").strip()\n",
    "        book_descriptions.append(description)\n",
    "        \n",
    "        genre = book_soup.find('ul', class_='breadcrumb').find_all('li')[2].get_text(strip=True)\n",
    "        book_genres.append(genre)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"UPC\": book_codes,\n",
    "        \"Title\": book_titles,\n",
    "        \"Price\": book_prices,\n",
    "        \"Rating\": book_ratings,\n",
    "        \"Availability\": book_availabilities,\n",
    "        \"Description\": book_descriptions,\n",
    "        \"Genre\": book_genres\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Call the function with a URL\n",
    "url = \"https://books.toscrape.com/\"\n",
    "books_df = extract_books_info(url)\n",
    "books_df\n",
    "# VICTOR CODE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b20fa6b0-29d7-4f51-8fbe-a1395d0b57c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://books.toscrape.com/catalogue/page-1.html',\n",
       " 'https://books.toscrape.com/catalogue/page-2.html',\n",
       " 'https://books.toscrape.com/catalogue/page-3.html',\n",
       " 'https://books.toscrape.com/catalogue/page-4.html',\n",
       " 'https://books.toscrape.com/catalogue/page-5.html',\n",
       " 'https://books.toscrape.com/catalogue/page-6.html',\n",
       " 'https://books.toscrape.com/catalogue/page-7.html',\n",
       " 'https://books.toscrape.com/catalogue/page-8.html',\n",
       " 'https://books.toscrape.com/catalogue/page-9.html',\n",
       " 'https://books.toscrape.com/catalogue/page-10.html',\n",
       " 'https://books.toscrape.com/catalogue/page-11.html',\n",
       " 'https://books.toscrape.com/catalogue/page-12.html',\n",
       " 'https://books.toscrape.com/catalogue/page-13.html',\n",
       " 'https://books.toscrape.com/catalogue/page-14.html',\n",
       " 'https://books.toscrape.com/catalogue/page-15.html',\n",
       " 'https://books.toscrape.com/catalogue/page-16.html',\n",
       " 'https://books.toscrape.com/catalogue/page-17.html',\n",
       " 'https://books.toscrape.com/catalogue/page-18.html',\n",
       " 'https://books.toscrape.com/catalogue/page-19.html',\n",
       " 'https://books.toscrape.com/catalogue/page-20.html',\n",
       " 'https://books.toscrape.com/catalogue/page-21.html',\n",
       " 'https://books.toscrape.com/catalogue/page-22.html',\n",
       " 'https://books.toscrape.com/catalogue/page-23.html',\n",
       " 'https://books.toscrape.com/catalogue/page-24.html',\n",
       " 'https://books.toscrape.com/catalogue/page-25.html',\n",
       " 'https://books.toscrape.com/catalogue/page-26.html',\n",
       " 'https://books.toscrape.com/catalogue/page-27.html',\n",
       " 'https://books.toscrape.com/catalogue/page-28.html',\n",
       " 'https://books.toscrape.com/catalogue/page-29.html',\n",
       " 'https://books.toscrape.com/catalogue/page-30.html',\n",
       " 'https://books.toscrape.com/catalogue/page-31.html',\n",
       " 'https://books.toscrape.com/catalogue/page-32.html',\n",
       " 'https://books.toscrape.com/catalogue/page-33.html',\n",
       " 'https://books.toscrape.com/catalogue/page-34.html',\n",
       " 'https://books.toscrape.com/catalogue/page-35.html',\n",
       " 'https://books.toscrape.com/catalogue/page-36.html',\n",
       " 'https://books.toscrape.com/catalogue/page-37.html',\n",
       " 'https://books.toscrape.com/catalogue/page-38.html',\n",
       " 'https://books.toscrape.com/catalogue/page-39.html',\n",
       " 'https://books.toscrape.com/catalogue/page-40.html',\n",
       " 'https://books.toscrape.com/catalogue/page-41.html',\n",
       " 'https://books.toscrape.com/catalogue/page-42.html',\n",
       " 'https://books.toscrape.com/catalogue/page-43.html',\n",
       " 'https://books.toscrape.com/catalogue/page-44.html',\n",
       " 'https://books.toscrape.com/catalogue/page-45.html',\n",
       " 'https://books.toscrape.com/catalogue/page-46.html',\n",
       " 'https://books.toscrape.com/catalogue/page-47.html',\n",
       " 'https://books.toscrape.com/catalogue/page-48.html',\n",
       " 'https://books.toscrape.com/catalogue/page-49.html']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = [f\"https://books.toscrape.com/catalogue/page-{pag}.html\" for pag in range(1,50)] # as we know we have 50 pages\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc4a23e0-e4cd-451e-8fa4-d3f2e8cc5da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPC</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a897fe39b1053632</td>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>It's hard to imagine a world without A Light i...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90fa61229261140a</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>\"Erotic and absorbing...Written with starling ...</td>\n",
       "      <td>Historical Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6957f44c3847a760</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Dans une France assez proche de la nôtre, un h...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4165285e1663650f</td>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>From a renowned historian comes a groundbreaki...</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f77dbf2323deb740</td>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>£22.65</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Patient Twenty-nine.A monster roams the halls ...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2597b5a345f45e1b</td>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>£33.34</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Drawing on his extensive experience evaluating...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e72a5dfc7e9267b2</td>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>£17.93</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>\"If you have a heart, if you have a soul, Kare...</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e10e1e165dc8be4a</td>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>£22.60</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>For readers of Laura Hillenbrand's Seabiscuit ...</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1dfe412b8ac00530</td>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>£52.15</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Praise for Aracelis Girmay:\"[Girmay's] every l...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0312262ecafa5a40</td>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>£13.99</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Since her assault, Miss Annette Chetwynd has b...</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30a7f60cd76ca58c</td>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>£20.66</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>This book is an important and complete collect...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ce6396b0f23f6ecc</td>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>£17.46</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Aaron Ledbetter’s future had been planned out ...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3b1c02bac2a429e6</td>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>£52.29</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Scott Pilgrim's life is totally sweet. He's 23...</td>\n",
       "      <td>Sequential Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a34ba96d4081e6a4</td>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>£35.02</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Punk's raw power rejuvenated rock, but by the ...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>deda3e61b9514b83</td>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>£57.25</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>This is the never-before-told story of the mus...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feb7cc7701ecf901</td>\n",
       "      <td>Olio</td>\n",
       "      <td>£23.88</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Part fact, part fiction, Tyehimba Jess's much ...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>e30f54cea9b38190</td>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>£37.59</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Andrew Barger, award-winning author and engine...</td>\n",
       "      <td>Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a18a4f574854aced</td>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>£51.33</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Libertarianism isn't about winning elections; ...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a22124811bfa8350</td>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>Three</td>\n",
       "      <td>In stock</td>\n",
       "      <td>“Wherever you go, whatever you do, just . . . ...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UPC                                              Title  \\\n",
       "0   a897fe39b1053632                               A Light in the Attic   \n",
       "1   90fa61229261140a                                 Tipping the Velvet   \n",
       "2   6957f44c3847a760                                         Soumission   \n",
       "3   e00eb4fd7b871a48                                      Sharp Objects   \n",
       "4   4165285e1663650f              Sapiens: A Brief History of Humankind   \n",
       "5   f77dbf2323deb740                                    The Requiem Red   \n",
       "6   2597b5a345f45e1b  The Dirty Little Secrets of Getting Your Dream...   \n",
       "7   e72a5dfc7e9267b2  The Coming Woman: A Novel Based on the Life of...   \n",
       "8   e10e1e165dc8be4a  The Boys in the Boat: Nine Americans and Their...   \n",
       "9   1dfe412b8ac00530                                    The Black Maria   \n",
       "10  0312262ecafa5a40     Starving Hearts (Triangular Trade Trilogy, #1)   \n",
       "11  30a7f60cd76ca58c                              Shakespeare's Sonnets   \n",
       "12  ce6396b0f23f6ecc                                        Set Me Free   \n",
       "13  3b1c02bac2a429e6  Scott Pilgrim's Precious Little Life (Scott Pi...   \n",
       "14  a34ba96d4081e6a4                          Rip it Up and Start Again   \n",
       "15  deda3e61b9514b83  Our Band Could Be Your Life: Scenes from the A...   \n",
       "16  feb7cc7701ecf901                                               Olio   \n",
       "17  e30f54cea9b38190  Mesaerion: The Best Science Fiction Stories 18...   \n",
       "18  a18a4f574854aced                       Libertarianism for Beginners   \n",
       "19  a22124811bfa8350                            It's Only the Himalayas   \n",
       "\n",
       "     Price Rating Availability  \\\n",
       "0   £51.77  Three     In stock   \n",
       "1   £53.74  Three     In stock   \n",
       "2   £50.10  Three     In stock   \n",
       "3   £47.82  Three     In stock   \n",
       "4   £54.23  Three     In stock   \n",
       "5   £22.65  Three     In stock   \n",
       "6   £33.34  Three     In stock   \n",
       "7   £17.93  Three     In stock   \n",
       "8   £22.60  Three     In stock   \n",
       "9   £52.15  Three     In stock   \n",
       "10  £13.99  Three     In stock   \n",
       "11  £20.66  Three     In stock   \n",
       "12  £17.46  Three     In stock   \n",
       "13  £52.29  Three     In stock   \n",
       "14  £35.02  Three     In stock   \n",
       "15  £57.25  Three     In stock   \n",
       "16  £23.88  Three     In stock   \n",
       "17  £37.59  Three     In stock   \n",
       "18  £51.33  Three     In stock   \n",
       "19  £45.17  Three     In stock   \n",
       "\n",
       "                                          Description               Genre  \n",
       "0   It's hard to imagine a world without A Light i...              Poetry  \n",
       "1   \"Erotic and absorbing...Written with starling ...  Historical Fiction  \n",
       "2   Dans une France assez proche de la nôtre, un h...             Fiction  \n",
       "3   WICKED above her hipbone, GIRL across her hear...             Mystery  \n",
       "4   From a renowned historian comes a groundbreaki...             History  \n",
       "5   Patient Twenty-nine.A monster roams the halls ...         Young Adult  \n",
       "6   Drawing on his extensive experience evaluating...            Business  \n",
       "7   \"If you have a heart, if you have a soul, Kare...             Default  \n",
       "8   For readers of Laura Hillenbrand's Seabiscuit ...             Default  \n",
       "9   Praise for Aracelis Girmay:\"[Girmay's] every l...              Poetry  \n",
       "10  Since her assault, Miss Annette Chetwynd has b...             Default  \n",
       "11  This book is an important and complete collect...              Poetry  \n",
       "12  Aaron Ledbetter’s future had been planned out ...         Young Adult  \n",
       "13  Scott Pilgrim's life is totally sweet. He's 23...      Sequential Art  \n",
       "14  Punk's raw power rejuvenated rock, but by the ...               Music  \n",
       "15  This is the never-before-told story of the mus...               Music  \n",
       "16  Part fact, part fiction, Tyehimba Jess's much ...              Poetry  \n",
       "17  Andrew Barger, award-winning author and engine...     Science Fiction  \n",
       "18  Libertarianism isn't about winning elections; ...            Politics  \n",
       "19  “Wherever you go, whatever you do, just . . . ...              Travel  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTS CODE\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def extract_books_info(url):\n",
    "    # Make a request to the provided URL\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Creating the lists to store the data\n",
    "    book_codes = []\n",
    "    book_titles = []\n",
    "    book_prices = []\n",
    "    book_ratings = []\n",
    "    book_availabilities = []\n",
    "    book_descriptions = []\n",
    "    book_genres = []\n",
    "\n",
    "    books = soup.find_all(class_=\"product_pod\")\n",
    "\n",
    "    for book in books:\n",
    "        book_link = \"https://books.toscrape.com/catalogue/\" + book.find('h3').find('a').get('href')\n",
    "        book_response = requests.get(book_link)\n",
    "        book_soup = BeautifulSoup(book_response.content, \"html.parser\")\n",
    "\n",
    "    for book in books:\n",
    "        title = book.find('h3').find('a').get('title')\n",
    "        book_titles.append(title)\n",
    "        \n",
    "        price = book.find('p', class_='price_color').get_text()\n",
    "        book_prices.append(price)\n",
    "        \n",
    "        rating = (\" \".join((soup.find('p', class_='star-rating')).get(\"class\"))).split()[1]\n",
    "        book_ratings.append(rating)\n",
    "\n",
    "        availability = book.find('p', class_='instock availability').get_text(strip=True)\n",
    "        book_availabilities.append(availability)\n",
    "\n",
    "        # Get book detail page URL - NEW\n",
    "        book_url = book.find('h3').find('a').get('href')\n",
    "        book_url = url + book_url.replace('../', '')  # ensures the URL is valid\n",
    "        \n",
    "         # Visit the book detail page - NEW\n",
    "        book_details_response = requests.get(book_url)\n",
    "        book_soup = BeautifulSoup(book_details_response.content, \"html.parser\")\n",
    "        \n",
    "        # Get the UPC - NEW\n",
    "        upc_table = book_soup.find('table', class_='table table-striped')\n",
    "        if upc_table:\n",
    "            upc = upc_table.find('tr').find('td').get_text()\n",
    "            book_codes.append(upc)\n",
    "        else:\n",
    "            book_codes.append('N/A')  # Or handle this case according to your need\n",
    "        \n",
    "        # Get the Description - NEW\n",
    "        description_tag = book_soup.find('meta', {'name': 'description'})\n",
    "        description = description_tag['content'].strip() if description_tag else \"Not available\"\n",
    "        book_descriptions.append(description)\n",
    "            \n",
    "        breadcrumb = book_soup.find('ul', class_='breadcrumb')\n",
    "        if breadcrumb:\n",
    "            genres = breadcrumb.find_all('li')\n",
    "            if len(genres) > 2:\n",
    "                genre = genres[2].get_text(strip=True)\n",
    "            else:\n",
    "                genre = \"Not available\"\n",
    "        else:\n",
    "            genre = \"Not available\"\n",
    "        book_genres.append(genre)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"UPC\": book_codes,\n",
    "        \"Title\": book_titles,\n",
    "        \"Price\": book_prices,\n",
    "        \"Rating\": book_ratings,\n",
    "        \"Availability\": book_availabilities,\n",
    "        \"Description\": book_descriptions,\n",
    "        \"Genre\": book_genres\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Call the function with a URL\n",
    "url = \"https://books.toscrape.com/\"\n",
    "books_df = extract_books_info(url)\n",
    "books_df\n",
    "# TEST CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d050320-1bd7-40df-9141-f754890fab20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-silent-sister-riley-macpherson-1_641/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000168B4361CD0>, 'Connection to books.toscrape.com timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    200\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    202\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[0;32m    203\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] Se produjo un error durante el intento de conexión ya que la parte conectada no respondió adecuadamente tras un periodo de tiempo, o bien se produjo un error en la conexión establecida ya que el host conectado no ha podido responder",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1095\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:693\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    692\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    694\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:208\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x00000168B4361CD0>, 'Connection to books.toscrape.com timed out. (connect timeout=None)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    845\u001b[0m )\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-silent-sister-riley-macpherson-1_641/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000168B4361CD0>, 'Connection to books.toscrape.com timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m all_books_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[1;32m----> 5\u001b[0m     page_df \u001b[38;5;241m=\u001b[39m extract_books_info(url)\n\u001b[0;32m      6\u001b[0m     all_books_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_books_df, page_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     all_books_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_books_df, page_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mextract_books_info\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m books:\n\u001b[0;32m     23\u001b[0m     book_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://books.toscrape.com/catalogue/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m book\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m     book_response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(book_link)\n\u001b[0;32m     25\u001b[0m     book_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(book_response\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m books:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[1;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='books.toscrape.com', port=443): Max retries exceeded with url: /catalogue/the-silent-sister-riley-macpherson-1_641/index.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000168B4361CD0>, 'Connection to books.toscrape.com timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "urls = [f\"https://books.toscrape.com/catalogue/page-{i}.html\" for i in range(1, 51)]\n",
    "all_books_df = pd.DataFrame()\n",
    "\n",
    "for url in urls:\n",
    "    page_df = extract_books_info(url)\n",
    "    all_books_df = pd.concat([all_books_df, page_df], ignore_index=True)\n",
    "    all_books_df = pd.concat([all_books_df, page_df], ignore_index=True)\n",
    "\n",
    "for page in range(1, 51):\n",
    "    url = base_url.format(page)\n",
    "    page_df = extract_books_info(url, min_rating, max_price)\n",
    "    all_books_df = pd.concat([all_books_df, page_df], ignore_index=True)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500efd5-62c9-47bf-97ae-8ef28565a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99844146-7ae6-4001-a9de-a1bb9402d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  UPC                                              Title  \\\n",
      "0    e72a5dfc7e9267b2  The Coming Woman: A Novel Based on the Life of...   \n",
      "1    ce6396b0f23f6ecc                                        Set Me Free   \n",
      "2    6258a1f6a6dcfe50  The Four Agreements: A Practical Guide to Pers...   \n",
      "3    6be3beb0793a53e7                                     Sophie's World   \n",
      "4    657fe5ead67a7767            Untitled Collection: Sabbath Poems 2014   \n",
      "..                ...                                                ...   \n",
      "111  29fc016c459aeb14              The Edge of Reason (Bridget Jones #2)   \n",
      "112  3301af038a720587                      The Complete Maus (Maus #1-2)   \n",
      "113  18b4545a5ed15581                            The Communist Manifesto   \n",
      "114  3a9a7c5895e82646                    Sister Sable (The Mad Queen #1)   \n",
      "115  19fec36a1dfb4c16  A Spy's Devotion (The Regency Spies of London #1)   \n",
      "\n",
      "     Price  Rating Availability  \\\n",
      "0    17.93       3     In stock   \n",
      "1    17.46       5     In stock   \n",
      "2    17.66       5     In stock   \n",
      "3    15.94       5     In stock   \n",
      "4    14.27       4     In stock   \n",
      "..     ...     ...          ...   \n",
      "111  19.18       4     In stock   \n",
      "112  10.64       3     In stock   \n",
      "113  14.76       3     In stock   \n",
      "114  13.33       3     In stock   \n",
      "115  16.97       5     In stock   \n",
      "\n",
      "                                           Description               Genre  \n",
      "0    \"If you have a heart, if you have a soul, Kare...             Default  \n",
      "1    Aaron Ledbetter’s future had been planned out ...         Young Adult  \n",
      "2    In The Four Agreements, don Miguel Ruiz reveal...        Spirituality  \n",
      "3    A page-turning novel that is also an explorati...          Philosophy  \n",
      "4    More than thirty-five years ago, when the weat...              Poetry  \n",
      "..                                                 ...                 ...  \n",
      "111  Monday 27 January“7:15 a.m. Hurrah! The wilder...      Womens Fiction  \n",
      "112  Combined for the first time here are Maus I: A...      Sequential Art  \n",
      "113  A rousing call to arms whose influence is stil...       Add a comment  \n",
      "114  THE FIRST TENET OF THE WIND: Do not get caught...             Fantasy  \n",
      "115  In England’s Regency era, manners and elegance...  Historical Fiction  \n",
      "\n",
      "[116 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tenacity import retry, wait_fixed, stop_after_attempt\n",
    "\n",
    "# Retry strategy for handling connection timeouts\n",
    "@retry(wait=wait_fixed(2), stop=stop_after_attempt(5))\n",
    "def fetch_url(url):\n",
    "    response = requests.get(url, timeout=10)\n",
    "    return response\n",
    "\n",
    "def extract_books_info(url, min_rating, max_price):\n",
    "    ratings_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "    books_list = []\n",
    "\n",
    "    response = fetch_url(url)  # Fetch URL with retry\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    books = soup.find_all(class_=\"product_pod\")\n",
    "\n",
    "    for book in books:\n",
    "        title = book.find('h3').find('a')['title']\n",
    "        price_text = book.find('p', class_='price_color').get_text()\n",
    "        price = float(price_text.replace('£', ''))\n",
    "\n",
    "        rating_text = book.find('p', class_='star-rating')['class'][1]\n",
    "        rating = ratings_map[rating_text]\n",
    "\n",
    "        if rating >= min_rating and price <= max_price:\n",
    "            book_link = \"https://books.toscrape.com/catalogue/\" + book.find('h3').find('a')['href']\n",
    "            book_response = fetch_url(book_link)\n",
    "            book_soup = BeautifulSoup(book_response.content, \"html.parser\")\n",
    "\n",
    "            upc_table = book_soup.find('table', class_='table table-striped')\n",
    "            upc = upc_table.find('tr').find('td').get_text() if upc_table else \"N/A\"\n",
    "\n",
    "            availability = book.find('p', class_='instock availability').get_text(strip=True)\n",
    "\n",
    "            description_tag = book_soup.find('meta', {'name': 'description'})\n",
    "            description = description_tag['content'].strip() if description_tag else \"Not available\"\n",
    "\n",
    "            breadcrumb = book_soup.find('ul', class_='breadcrumb')\n",
    "            genre = breadcrumb.find_all('li')[2].get_text(strip=True) if breadcrumb else \"Not available\"\n",
    "\n",
    "            books_list.append({\n",
    "                \"UPC\": upc,\n",
    "                \"Title\": title,\n",
    "                \"Price\": price,\n",
    "                \"Rating\": rating,\n",
    "                \"Availability\": availability,\n",
    "                \"Description\": description,\n",
    "                \"Genre\": genre\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(books_list)\n",
    "\n",
    "# Main function to iterate through pages\n",
    "def scrape_books(min_rating, max_price):\n",
    "    base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "    all_books_df = pd.DataFrame()\n",
    "\n",
    "    for page in range(1, 51):\n",
    "        url = base_url.format(page)\n",
    "        page_df = extract_books_info(url, min_rating, max_price)\n",
    "        all_books_df = pd.concat([all_books_df, page_df], ignore_index=True)\n",
    "        time.sleep(1)  # Sleep for 1 second between requests\n",
    "\n",
    "    return all_books_df\n",
    "\n",
    "# Example call\n",
    "books_df = scrape_books(min_rating=3, max_price=20.00)\n",
    "print(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb5d4c2-b7f5-44fb-8c6b-9e4a92e4c5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPC</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e72a5dfc7e9267b2</td>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>17.93</td>\n",
       "      <td>3</td>\n",
       "      <td>In stock</td>\n",
       "      <td>\"If you have a heart, if you have a soul, Kare...</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ce6396b0f23f6ecc</td>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>17.46</td>\n",
       "      <td>5</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Aaron Ledbetter’s future had been planned out ...</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6258a1f6a6dcfe50</td>\n",
       "      <td>The Four Agreements: A Practical Guide to Pers...</td>\n",
       "      <td>17.66</td>\n",
       "      <td>5</td>\n",
       "      <td>In stock</td>\n",
       "      <td>In The Four Agreements, don Miguel Ruiz reveal...</td>\n",
       "      <td>Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6be3beb0793a53e7</td>\n",
       "      <td>Sophie's World</td>\n",
       "      <td>15.94</td>\n",
       "      <td>5</td>\n",
       "      <td>In stock</td>\n",
       "      <td>A page-turning novel that is also an explorati...</td>\n",
       "      <td>Philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>657fe5ead67a7767</td>\n",
       "      <td>Untitled Collection: Sabbath Poems 2014</td>\n",
       "      <td>14.27</td>\n",
       "      <td>4</td>\n",
       "      <td>In stock</td>\n",
       "      <td>More than thirty-five years ago, when the weat...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>29fc016c459aeb14</td>\n",
       "      <td>The Edge of Reason (Bridget Jones #2)</td>\n",
       "      <td>19.18</td>\n",
       "      <td>4</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Monday 27 January“7:15 a.m. Hurrah! The wilder...</td>\n",
       "      <td>Womens Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3301af038a720587</td>\n",
       "      <td>The Complete Maus (Maus #1-2)</td>\n",
       "      <td>10.64</td>\n",
       "      <td>3</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Combined for the first time here are Maus I: A...</td>\n",
       "      <td>Sequential Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>18b4545a5ed15581</td>\n",
       "      <td>The Communist Manifesto</td>\n",
       "      <td>14.76</td>\n",
       "      <td>3</td>\n",
       "      <td>In stock</td>\n",
       "      <td>A rousing call to arms whose influence is stil...</td>\n",
       "      <td>Add a comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3a9a7c5895e82646</td>\n",
       "      <td>Sister Sable (The Mad Queen #1)</td>\n",
       "      <td>13.33</td>\n",
       "      <td>3</td>\n",
       "      <td>In stock</td>\n",
       "      <td>THE FIRST TENET OF THE WIND: Do not get caught...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>19fec36a1dfb4c16</td>\n",
       "      <td>A Spy's Devotion (The Regency Spies of London #1)</td>\n",
       "      <td>16.97</td>\n",
       "      <td>5</td>\n",
       "      <td>In stock</td>\n",
       "      <td>In England’s Regency era, manners and elegance...</td>\n",
       "      <td>Historical Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  UPC                                              Title  \\\n",
       "0    e72a5dfc7e9267b2  The Coming Woman: A Novel Based on the Life of...   \n",
       "1    ce6396b0f23f6ecc                                        Set Me Free   \n",
       "2    6258a1f6a6dcfe50  The Four Agreements: A Practical Guide to Pers...   \n",
       "3    6be3beb0793a53e7                                     Sophie's World   \n",
       "4    657fe5ead67a7767            Untitled Collection: Sabbath Poems 2014   \n",
       "..                ...                                                ...   \n",
       "111  29fc016c459aeb14              The Edge of Reason (Bridget Jones #2)   \n",
       "112  3301af038a720587                      The Complete Maus (Maus #1-2)   \n",
       "113  18b4545a5ed15581                            The Communist Manifesto   \n",
       "114  3a9a7c5895e82646                    Sister Sable (The Mad Queen #1)   \n",
       "115  19fec36a1dfb4c16  A Spy's Devotion (The Regency Spies of London #1)   \n",
       "\n",
       "     Price  Rating Availability  \\\n",
       "0    17.93       3     In stock   \n",
       "1    17.46       5     In stock   \n",
       "2    17.66       5     In stock   \n",
       "3    15.94       5     In stock   \n",
       "4    14.27       4     In stock   \n",
       "..     ...     ...          ...   \n",
       "111  19.18       4     In stock   \n",
       "112  10.64       3     In stock   \n",
       "113  14.76       3     In stock   \n",
       "114  13.33       3     In stock   \n",
       "115  16.97       5     In stock   \n",
       "\n",
       "                                           Description               Genre  \n",
       "0    \"If you have a heart, if you have a soul, Kare...             Default  \n",
       "1    Aaron Ledbetter’s future had been planned out ...         Young Adult  \n",
       "2    In The Four Agreements, don Miguel Ruiz reveal...        Spirituality  \n",
       "3    A page-turning novel that is also an explorati...          Philosophy  \n",
       "4    More than thirty-five years ago, when the weat...              Poetry  \n",
       "..                                                 ...                 ...  \n",
       "111  Monday 27 January“7:15 a.m. Hurrah! The wilder...      Womens Fiction  \n",
       "112  Combined for the first time here are Maus I: A...      Sequential Art  \n",
       "113  A rousing call to arms whose influence is stil...       Add a comment  \n",
       "114  THE FIRST TENET OF THE WIND: Do not get caught...             Fantasy  \n",
       "115  In England’s Regency era, manners and elegance...  Historical Fiction  \n",
       "\n",
       "[116 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36745d-6ef6-43e6-a071-16833420f631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
